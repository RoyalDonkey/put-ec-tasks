\documentclass[14pt]{article}

% Basic packages
\usepackage{subfiles}
\usepackage{extsizes}
\usepackage[quiet]{fontspec}
\usepackage{unicode-math}
\usepackage[margin=2cm]{geometry}
\usepackage{hyperref}
\usepackage[nameinlink]{cleveref}
\usepackage{fancyhdr, lastpage}
\usepackage{multirow, multicol}
\usepackage{longtable}
\usepackage{siunitx}
\usepackage{amsmath, amssymb}
\usepackage{soul}
\usepackage{float}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{pdfpages}
\usepackage{changepage}

% Font config
\defaultfontfeatures{Scale=MatchUppercase}
\setmainfont{Libertinus Serif}
\setsansfont{Carlito}
\setmonofont{DejaVu Sans Mono}
\setmathfont{Libertinus Math}
\setul{1pt}{.4pt}

% Page layout config
\let\OLDTITLE\title
\renewcommand{\title}[1]{\OLDTITLE{#1}\newcommand{\thetitle}{#1}}
\pagestyle{fancy}
\lhead{\thetitle}
\cfoot{Page \thepage\ of \pageref{LastPage}}

% Hyperref config
\hypersetup{colorlinks=true, urlcolor=blue}
\urlstyle{same}

% Minted config
\usepackage[outputdir={\detokenize{OUTDIR}}]{minted}
\renewcommand{\theFancyVerbLine}{\sffamily
\textcolor[rgb]{0.4,0.4,0.4}{\small \arabic{FancyVerbLine}}}
\setminted{autogobble,obeytabs,frame=single,highlightcolor=yellow}
\renewcommand{\listingscaption}{Source}

% \usepackage[singlefile, pdf]{graphviz}

\title{Evolutionary Computation Lab VI}
\author{Piotr Kaszubski 148283}
\date{Monday, December  4, 2023}

\begin{document}
\maketitle
\tableofcontents
\newpage

\section{Problem description}
We are given three columns of integers with a row for each node. The first two
columns contain \verb`x` and \verb`y` coordinates of the node positions in a
plane. The third column contains node costs.

\begin{enumerate}
	\item Select exactly 50\% of the nodes (if the number of nodes is odd we
		round the number of nodes to be selected up).
	\item Form a Hamiltonian cycle (closed path) through this set of nodes such
		that the sum of the total length of the path plus the total cost of the
		selected nodes is minimized. The distances between nodes are calculated
		as Euclidean distances rounded mathematically to integer values.
\end{enumerate}

The distance matrix should be calculated just after reading an instance and
then only the distance matrix (no nodes coordinates) should be accessed by
optimization methods to allow instances defined only by distance matrices.

\section{Pseudocode}
\subsection{Perturbation}
I define a perturbation as applying \textbf{10} uniformly random (with
replacement) swaps (can be both intra- and inter-swaps).

This is the most important part of my algorithm that commenses after the
initial linear search (expressed in Python for ease of reading):
\begin{listing}[H]
	\begin{minted}[highlightlines={}]{python}
		perturb_delta = -1;
		anneal_temp = 600.0 * 1.2;
		while perturb_delta < anneal_temp and clock() < deadline:
			score_before = evaluate(graph)
			perturb(graph);
			lsearch_steepest(graph);
			score_after = evaluate(graph)
			perturb_delta = score_after - score_before;
			anneal_temp /= 1.2;
	\end{minted}
\end{listing}
\vspace{-1cm}
Basically, I enter a loop where a perturbation is applied, linear search
performed, and then if the delta is lower than some threshold, we continue.
This threshold starts at \textbf{600.0} and is divided by \textbf{1.2} after
every successful perturbation.

The parameters \textbf{10}, \textbf{600.0} and \textbf{1.2} were chosen
experimentally.

\subsection{Perturbation (simpler)}
After presenting the idea of the perturbation with annealing on the labs, I
found out that I slightly misunderstood the requirements, and, more
importantly, I learned that a much simpler version of this algorithm works
better:
\begin{listing}[H]
	\begin{minted}[highlightlines={}]{python}
		while clock() < deadline:
			perturb(graph);
			lsearch_steepest(graph);
	\end{minted}
\end{listing}
\vspace{-1cm}
\noindent
The report will generally focus on the simpler approach, as it was the one
intended for this report, and the one that gives better results. However, I
will still include the results of the more complicated variant. To distinguish
between the two, the more complicated one will be referred to as
"i$_a$ls-steepest-random" or "I$_a$LS" (subscript "a" for "annealing").

\section{Results}

\begin{longtable}[c]{|c|cc|}
	\hline
	\multirow{2}*{\textbf{ALG.}} & \textbf{TSPA} & \textbf{TSPC} \\
	& \textbf{TSPB} & \textbf{TSPD} \\
	\hline
	\endfirsthead
	\hline
	\multirow{2}*{\textbf{ALG.}} & \textbf{TSPA} & \textbf{TSPC} \\
	& \textbf{TSPB} & \textbf{TSPD} \\
	\hline
	\endhead
	\multirow{2}*{ls-steepest-random} & 77,866 (75,315--81,017) & 51,453 (49,257--53,785) \\
	& 71,322 (68,623--76,002) & 48,234 (45,351--51,534) \\
	\hline
	\multirow{2}*{lsc-steepest-random} & 89,127 (82,350--101,152) & 62,892 (55,074--74,956) \\
	& 84,469 (74,393--96,069) & 60,203 (51,897--67,824) \\
	\hline
	\multirow{2}*{lsd-steepest-random} & 77,866 (75,315--81,017) & 51,453 (49,257--53,785) \\
	& 71,322 (68,623--76,002) & 48,234 (45,351--51,534) \\
	\hline
	\multirow{2}*{lscd-steepest-random} & 89,127 (82,350--101,152) & 62,892 (55,074--74,956) \\
	& 84,469 (74,393--96,069) & 60,203 (51,897--67,824) \\
	\hline
	\multirow{2}*{msls-steepest-random} & 75,048 (74,178--75,644) & 49,128 (48,311--49,620) \\
	& 68,211 (67,828--68,622) & 45,649 (45,075--46,032) \\
	\hline
	\multirow{2}*{ils-steepest-random} & 74,255 (73,754--74,535) & 48,312 (47,936--48,646) \\
	& 67,389 (67,008--67,744) & 44,616 (44,105--45,127) \\
	\hline
	\multirow{2}*{i$_a$ls-steepest-random} & 74,893 (74,137--75,593) & 48,969 (48,662--49,308) \\
	& 68,070 (67,676--68,496) & 45,505 (45,016--46,114) \\
	\hline
	\caption{Average, minimum and maximum scores of found solutions}
\end{longtable}

\begin{longtable}[c]{|c|cc|}
	\hline
	\multirow{2}*{\textbf{ALG.}} & \textbf{TSPA} & \textbf{TSPC} \\
	& \textbf{TSPB} & \textbf{TSPD} \\
	\hline
	\endfirsthead
	\hline
	\multirow{2}*{\textbf{ALG.}} & \textbf{TSPA} & \textbf{TSPC} \\
	& \textbf{TSPB} & \textbf{TSPD} \\
	\hline
	\endhead
	\multirow{2}*{ls-steepest-random} & 85.737 (71.796--105.250) & 85.470 (72.226--98.981) \\
	& 88.181 (73.757--107.447) & 87.450 (67.483--102.099) \\
	\hline
	\multirow{2}*{lsc-steepest-random} & 21.973 (17.070--28.766) & 20.936 (15.504--30.904) \\
	& 22.002 (17.069--29.329) & 21.179 (15.651--28.530) \\
	\hline
	\multirow{2}*{lsd-steepest-random} & 43.684 (33.639--66.647) & 42.885 (33.038--57.912) \\
	& 43.794 (35.071--54.709) & 43.747 (30.598--74.864) \\
	\hline
	\multirow{2}*{lscd-steepest-random} & 28.267 (18.670--39.157) & 27.632 (18.752--39.882) \\
	& 28.695 (19.072--38.583) & 27.669 (19.578--40.003) \\
	\hline
	\caption{Average, minimum, maximum running times per instance (ms)}
\end{longtable}

\begin{longtable}[c]{|c|cc|}
	\hline
	\multirow{2}*{\textbf{ALG.}} & \textbf{TSPA} & \textbf{TSPC} \\
	& \textbf{TSPB} & \textbf{TSPD} \\
	\hline
	\endfirsthead
	\hline
	\multirow{2}*{\textbf{ALG.}} & \textbf{TSPA} & \textbf{TSPC} \\
	& \textbf{TSPB} & \textbf{TSPD} \\
	\hline
	\endhead
	\multirow{2}*{msls-steepest-random} & 16.339 (15.744--16.838) & 16.064 (15.530--16.725) \\
	& 16.606 (16.074--17.191) & 16.282 (15.941--16.693) \\
	\hline
	\multirow{2}*{ils-steepest-random} & 16.327 (16.323--16.337) & 16.328 (16.324--16.334) \\
	& 16.328 (16.323--16.337) & 16.328 (16.323--16.338) \\
	\hline
	\multirow{2}*{i$_a$ls-steepest-random} & 16.335 (16.323--16.387) & 16.342 (16.323--16.395) \\
	& 16.333 (16.324--16.380) & 16.342 (16.323--16.403) \\
	\hline
	\caption{Average, minimum, maximum running times for MSLS, ILS and I$_a$LS (s)}
\end{longtable}

\begin{longtable}[c]{|c|cc|}
	\hline
	\multirow{2}*{\textbf{ALG.}} & \textbf{TSPA} & \textbf{TSPC} \\
	& \textbf{TSPB} & \textbf{TSPD} \\
	\hline
	\endfirsthead
	\hline
	\multirow{2}*{\textbf{ALG.}} & \textbf{TSPA} & \textbf{TSPC} \\
	& \textbf{TSPB} & \textbf{TSPD} \\
	\hline
	\endhead
	\multirow{2}*{ils-steepest-random} & 1,868.5 (1,805--1,920) & 1,663.0 (1,601--1,835) \\
	& 1,774.8 (1,599--1,857) & 1,642.5 (1,535--1,829) \\
	\hline
	\multirow{2}*{i$_a$ls-steepest-random} & 1,149.3 (1,091--1,209) & 1,207.8 (1,139--1,249) \\
	& 1,117.7 (1,056--1,178) & 1,150.0 (1,067--1,194) \\
	\hline
	\caption{Average, minimum, maximum number of times linear search was run}
	\label{tab:lsearch_counts}
\end{longtable}

\newpage
\subsection{Best solutions}
All best solutions are available
\href{https://github.com/RoyalDonkey/put-ec-tasks/tree/7882d44ac2786cd0d4bd691569a498d2ae1f6caa/task6/results}
{in the repository}, as always. I export them as \verb`*.graph` files, which
follow a very simple text encoding:
\begin{listing}[H]
	\begin{minted}[highlightlines={}]{text}
			<no_vacant_nodes>;<no_active_nodes>
			<x>;<y>;<cost>                            \
			<x>;<y>;<cost>                             | vacant nodes
			...                                       /
			<x>;<y>;<cost>                            \
			<x>;<y>;<cost>                             | active nodes
			...                                       /
	\end{minted}
\end{listing}
\vspace{-1cm}
"Vacant" nodes are the nodes not used in the solution. "active" nodes are the
ones in the solution. Since all graphs consist of 200 nodes and all solutions
are 50\% active, to find the list of nodes in the solution, simply look at the
last 100 lines of each \verb`*.graph` file.

\newpage
\section{Visualizations}

\newcommand{\visualization}[3]{%
\begin{figure}[H]%
	\includegraphics[width=\linewidth]{results/best_#2_#1.pdf}%
	\vspace{-12mm}%
	\caption{Best #2 solution to #1 (#3)}%
\end{figure}%
}

\subsection{TSPA.csv}
\visualization{TSPA}{msls-steepest-random}{74,178}
\visualization{TSPA}{ils-steepest-random}{73,754}

\subsection{TSPB.csv}
\visualization{TSPB}{msls-steepest-random}{67.828}
\visualization{TSPB}{ils-steepest-random}{67,008}

\subsection{TSPC.csv}
\visualization{TSPC}{msls-steepest-random}{48,311}
\visualization{TSPC}{ils-steepest-random}{47,936}

\subsection{TSPD.csv}
\visualization{TSPD}{msls-steepest-random}{45,075}
\visualization{TSPD}{ils-steepest-random}{44,105}

\section{Source code}
The source code for all the experiments and this report is hosted on GitHub: \\
\url{https://github.com/RoyalDonkey/put-ec-tasks}

\section{Conclusions}
\subsection{Original conclusions (before simpler perturbation)}
As expected, iterated linear search with perturbations outperformed the more
naïve multiple-start local search. The margin isn't great, but considering
the flexibility of I$_a$LS (tweakable perturbation function and timeout), it is a
significantly more versatile approach, while still being very simple in its
concept.

Despite their promising results, both MSLS and I$_a$LS can't really be compared
with the previously tested techniques, due to the many times longer execution
time that was given to them. In the case of I$_a$LS, this could of course be
tweaked, but capping it at 1 linear search's time would make it identical to
just linear search. Both MSLS and I$_a$LS are really only viable as extensions to
linear search, with the assumption that we have enough time for many runs.

\subsection{Additional conclusions (after adding simpler perturbation)}
Well, simpler means better a lot of the time, and this is one of those times.
There is a very noticeable improvement in results, which can be attributed to
the increased number of instances that are explored. No time is wasted on extra
evaluations, comparisons, etc. This is very clearly visible on
\Cref{tab:lsearch_counts}, where ILS manages to run linear search many more
times.

\end{document}
